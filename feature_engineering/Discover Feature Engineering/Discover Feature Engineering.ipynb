{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Discover Feature Engineering\n",
    "***\n",
    "[原文链接](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/, \"Discover Feature Engineering, How to Engineer Features and How to Get Good at It.\")\n",
    "\n",
    "**特征工程**是一个非正式的主题, 但是它在应用机器学习中至关重要.\n",
    "\n",
    "在写本文时, 我广泛深入参考了所有我能得到的资源.\n",
    "\n",
    "本文会让你知道什么是特征工程, 它能解决什么问题, 它为什么重要, 如何进行特征工程, 还有谁擅长特征工程, 以及如何进一步学习特征工程.\n",
    "\n",
    "如果你阅读过关于特征工程的相关文章, 我希望是下面这篇:\n",
    "> 特征工程是一个似乎不值得任何论文或者书籍, 甚至书中的一个章节所描述的主题, 但是它对于一个成功的机器学习应用至关重要. [...]大多数成功的机器学习应用实际上是特征工程的成功, 能够得到学习器能理解的特征.\n",
    "\n",
    "> --Scott Lockin, in [\"Neglected machine learning ideas\"](https://scottlocklin.wordpress.com/2014/07/22/neglected-machine-learning-ideas/)\n",
    "\n",
    "## 目录\n",
    "***\n",
    "1. [特征工程要解决的问题](#1)\n",
    "2. [特征工程的重要性](#2)\n",
    "3. [什么是特征工程?](#3)\n",
    "4. [特征工程的子问题](#4)\n",
    "5. [特征工程的流程](#5)\n",
    "6. [特征工程实例](#6)\n",
    "\n",
    "<h2 id=\"1\"> 1. 特征工程要解决的问题 </h2>\n",
    "***\n",
    "当你的目标是从预测模型中获得最好的结果, 你需要最大程度的利用好手上的资源. 这包括把你所使用算法的性能发挥到极致, 这也包括从你的数据中获取尽可能多的有用信息. **如何从你的数据中获取尽可能多的有用信息呢?** 这正是特征工程索要解决的问题.\n",
    "> 所有机器学习算法的成功实际上依赖于你是如何表示数据的.\n",
    "\n",
    "> Actually the success of all Machine Learning algorithms depends on how you present the data.\n",
    "\n",
    "> Mohammad Pezeshki, answer to [\"What are some general tips on feature selection and engineering that every data scientist should know?\"](https://www.quora.com/What-are-some-general-tips-on-feature-selection-and-engineering-that-every-data-scientist-should-know)\n",
    "\n",
    "<h2 id=\"2\"> 2. 特征工程的重要性 </h2>\n",
    "***\n",
    "数据的特征将直接影响你使用的预测模型和你能够通过该特征获得的结果.\n",
    "\n",
    "可以这么说: 你选择的特征越好, 你所获得的结果就越好. 这是真的, 但是也会有误导.\n",
    "\n",
    "你所获得的结果是你选择的模型, 你拥有的数据和你选择的特征这些因素共同决定的. 还有你所要解决的问题, 和你用来估计准确率的目标函数也起一定的作用. 你的结果依赖于许多相互关联的属性.\n",
    "\n",
    "你需要能够描述隐藏在数据中的结构的特征.\n",
    "\n",
    "**Better features means flexibility.**\n",
    "\n",
    "你可以选择不是那么合适的模型, 但仍然可以获得很好的结果. 选择了好的特征之后的灵活性体现在: 允许你使用复杂度更低(运行更快, 更易理解和维护)的模型.\n",
    "\n",
    "**Better features means simpler models.**\n",
    "\n",
    "同样的, 你可以选择不是最优的参数, 但仍然可以获得很好的结果.\n",
    "\n",
    "选择好的特征, 你能够离问题的本身更进一步.\n",
    "\n",
    "**Better features means better results.**\n",
    "\n",
    "> The algorithms we used are very standard for Kagglers. [...] We spent most of our efforts in feature engineering.\n",
    "\n",
    "> --Xavier Conort, on [\"Q&A with XavierConort\"](http://blog.kaggle.com/2013/04/10/qa-with-xavier-conort/)\n",
    "\n",
    "<h2 id=\"3\"> 3. 什么是特征工程? </h2>\n",
    "***\n",
    "以下是我自己对特征工程的定义:\n",
    "> Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\n",
    "\n",
    "Tomasz Malisiewicz, answer to [“What is feature engineering?”](https://www.quora.com/What-is-feature-engineering)\n",
    "> feature engineering is manually designing what the input x's should be.\n",
    "\n",
    "### 特征工程是一个表示问题(Feature Engineering is a Representation Problem)\n",
    "***\n",
    "机器学习算法针对一个问题, 从样本数据中学习得到一个解决方法. 在这种解释中, 特征工程要解决: 为了学习得到一个解决方法, 什么是样本数据的最好表示? 表示问题很难, 因为事先不知道最好的表示是什么.\n",
    "> you have to turn your inputs into things the algorithm can understand.\n",
    "\n",
    "> --Shayne Miel, answer to [\"What is the intuitive explanation of feature engineering in machine learning?\"](https://www.quora.com/What-is-feature-engineering?redirected_qid=2437911)\n",
    "\n",
    "### 特征工程是一种艺术(Feature Engineering is an Art)\n",
    "***\n",
    "特征工程的掌握需要大量实践, 以及研究别人做得好的一些案例.\n",
    "> ...some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used.\n",
    "\n",
    "> --Pedro Domingos, in [\"A Few Useful Things to Know about Machine Learning\"](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
    "\n",
    "<h2 id=\"4\"> 4. 特征工程的子问题 </h2>\n",
    "***\n",
    "通常容易认为特征工程只是一件事情. 例如: 我自己在很长一段时间, 都认为特征工程是特征构造. 我在做特征工程时, 我会问自己\"我该如何分解和组合原始数据来更好的描述问题?\", 这个目标是对的, 但是方法有很多种.\n",
    "\n",
    "在这一小节中, 我们会介绍多种方法及其对应的子问题. 每一种方法都需要花大量时间研究和实践.\n",
    "\n",
    "### 特征: 对建模任务有用的属性(Feature: An attribute useful for your modeling task)\n",
    "***\n",
    "电子表格式的数据通常包括很多行, 每一行包含很多列, 其中每一列(也叫属性)能够作为一个特征.\n",
    "\n",
    "作者认为, 特征是对学习问题有意义的属性, 不是所有属性都能成为特征.\n",
    "\n",
    "在计算机视觉中, 一幅图像是一个样本, 其中的特征可以是图像中的一条线. 在自然语言处理中, 一个文档是一个样本, 短语或者某个词的个数可以是一个特征. 在语音识别中, 一段音频是一个样本, 单个词语或者音素.\n",
    "\n",
    "### 特征重要性: 特征有用程度的估计(Feature Importance: An estimate of the usefulness of a feature)\n",
    "***\n",
    "你可以客观的估计一个特征的重要程度.\n",
    "\n",
    "特征重要性能够作为选择特征的先导条件. 每个特征都会有一个得分, 然后根据得分排序. 那些得分最高的特征被选用, 其它特征被忽略.\n",
    "\n",
    "特征重要性得分也给你提供必要的信息来提取或者构造新的特征.\n",
    "\n",
    "如果特征与预测变量有强相关关系, 那么该特征可能是重要的. 相关系数和其他单因素方法是常用的方法.\n",
    "\n",
    "很多复杂的预测模型在构建模型的过程中在内部执行特征选择. 比如: MARS, Random Forest 和 Gradient Boosted Machines. \n",
    "\n",
    "### 特征提取: 从原始数据中自动生成新特征(Feature Extraction: The automatic construction of new features from raw data)\n",
    "***\n",
    "有些样本原始数据难以直接用作模型的训练. 例如: 图像, 音频, 文本数据, 这些数据仅仅能够容易的包含在一个拥有百万属性的电子表格数据中.\n",
    "\n",
    "特征提取是一个自动地把这类数据的维度降到能够被用来训练的一个子集的过程.\n",
    "\n",
    "对于电子表格式数据, 特征提取可能包括投影方法, 例如: PCA 和 无监督聚类方法. 对于图像数据, 特征提取可能包括线或者边缘的检测. 根据领域的不同, 图像, 视频和音频数据能够使用许多相同类型的 DSP 方法.\n",
    "\n",
    "### 特征选择(Feature Selection: From many features to a few that are useful)\n",
    "***\n",
    "### 特征构造(Feature Construction: The manual construction of new features from raw data)\n",
    "***\n",
    "### 特征学习(Feature Learning: The automatic identification and use of features in raw data)\n",
    "\n",
    "<h2 id=\"5\"> 5. 特征工程的流程 </h2>\n",
    "***\n",
    "### 机器学习的流程(Process of Machine Learning)\n",
    "***\n",
    "机器学习包括很多流程: 首先是问题定义, 然后是数据选择和准备, 接下来是模型准备,评估和调参, 最后是结果呈现.\n",
    "\n",
    "大致流程如下:\n",
    "1. (tasks before here...)\n",
    "2. 选择数据: 整合数据生成数据集;\n",
    "3. 数据预处理: 对数据进行格式化, 清理, 采样等工作;\n",
    "4. 数据变换: 特征工程出现在这里;\n",
    "5. 生成模型: 创建模型, 评估和调整模型;\n",
    "6. (tasks after here...)\n",
    "\n",
    "### 特征工程的迭代流程(Iterative Process of Feature Engineering)\n",
    "***\n",
    "大致流程如下:\n",
    "1. 头脑风暴特征(Brainstorm features): 深入研究问题, 查看数据, 研究其他问题的特征工程如何实施并看看有什么可以借鉴.\n",
    "2. 设计特征(Devise features): 根据不同的问题的情况, 你可以使用自动特征提取(automatic feature extraction), 或者手工特征构造(manual feature construction), 也可以是二者的混合.\n",
    "3. 选择特征(Select features): 使用不同特征重要性得分和特征选择方法来生成模型.\n",
    "4. 评估模型(Evaluate models): 估计模型对于未见数据预测的性能好坏.\n",
    "\n",
    "<h2 id=\"6\"> 6. 特征工程实例 </h2>\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
