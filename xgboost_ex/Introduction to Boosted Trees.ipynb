{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 提升树(Boosted Trees)简介\n",
    "***\n",
    "\"Extreme Gradient Boosting\" 简称为: **XGBoost**, \"Gradient Boosting\" 首次由 Friedman 在论文 \"Greedy Function Approximation: A Gradient Boosting Machine\" 中提出, XGBoost 是基于这个原始模型的. 本文是关于梯度提升树(Gradient Boosted Trees)的教程, 大多数内容来源于 XGBoost 作者的[幻灯片](https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf).\n",
    "\n",
    "GBM(Boosted Trees)已经提出有一段时间了, 所以有很多关于该主题的资料. 本教程试图使用监督学习的基本概念解释提升树. 这样的解释更加清晰, 更加正式, 也更能启发使用者创造性的使用 XGBoost.\n",
    "\n",
    "## 1. 监督学习基本概念\n",
    "***\n",
    "XGBoost 是用来解决监督学习问题的, 即: 使用训练数据(带有多维特征) $x_i$ 去预测目标变量 $y_i$. 在深入介绍提升树之前, 先复习一下监督学习的基本概念.\n",
    "\n",
    "### 1.1 模型与参数\n",
    "***\n",
    "在监督学习中**模型**这个概念通常指的是: 如何通过给定的 $x_i$ 去预测 $y_i$ 的数学结构(我狭义的理解为函数好了). 例如: 一个常见的模型是线性回归, 预测值由输入特征的加权线性组合给出 $\\hat{y}_i = \\sum_j \\theta_{j} x_{ij}$. 根据任务的不同(回归或者分类), 预测值有不同的解释. 例如: 在 Logistic Regression 中, 通过转换(比如: sigmoid function)获得模型预测样本为正类的概率; 而当我们想给输出排序时, 该预测值可以作为排序指标.\n",
    "\n",
    "**参数**是需要我们从数据中学习得到的. 在线性回归问题中, 参数是 $\\theta$. 通常我们将会使用 $\\theta$ 来表示参数(在一个模型中常常有多个参数).\n",
    "\n",
    "### 1.2 目标函数: 训练损失 + 正则化\n",
    "***\n",
    "基于对 &y_i& 的不同理解, 存在诸如: 回归, 分类, 排序等问题. 在给定训练数据的条件下, 我们需要找一种方法来获得最佳的参数. 为了达到这个目的, 我们需要定义所谓的**目标函数**, 该函数作为给定参数条件下的模型性能评价指标.\n",
    "\n",
    "关于目标函数非常重要的一点就是, 它通常必须包含两部分: 训练损失和正则化. \n",
    "\n",
    "$$obj(\\theta)=L(\\theta)+\\Omega(\\theta)$$\n",
    "\n",
    "这里, $L$ 是训练损失函数, $\\Omega$ 是正则化项. 训练损失体现模型在训练数据上的预测性能. 例如: 一种常见的训练损失是均方差(Mean Squared Error, MSE).\n",
    "\n",
    "$$L(\\theta)=\\sum_i (y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "另一种常用作 Logistic Regression 的损失函数是 logistic-loss.\n",
    "\n",
    "$$L(\\theta)=\\sum_i [y_i \\ln{(1+e^{-\\hat{y}_i})} + (1-y_i) \\ln{(1+e^{\\hat{y}_i})}]$$\n",
    "\n",
    "**正则化项**容易忘记添加. **正则化项**控制着模型的复杂度以防止过拟合. 这个听起来有点抽象, 让我们来看一下图片中的例子. 下图左上角显示给定的数据, 你需要找到一个函数来拟合这个阶跃函数(step function). 你认为以下三个答案中哪个是最好的?\n",
    "\n",
    "![1.png](./resources/1.png)\n",
    "\n",
    "正确的答案标记为红色. 请思考这是否是合理的. 一般的原则是: 我们想得到一个既简单又有足够预测能力的模型. 在机器学习中这种折中也称为: 偏差-方差折中(bias-variance tradeoff).\n",
    "\n",
    "### 1.3 为什么介绍一般的原则?\n",
    "***\n",
    "以上介绍的概念构成了监督学习的基本元素. 你应该能够描述提升树(Boosted Trees)和随机森林(Random Forest)之间的相同点和区别. 理解一般性原则有助于认清我们学习的目标和更好的理解诸如: 剪纸(pruning)和平滑(smoothing)这类启发式算法背后的逻辑.\n",
    "\n",
    "## 2. 树集成(Tree Ensemble)\n",
    "***\n",
    "现在我们介绍监督学习的基本元素, 让我们从树开始. 首先, 学习 XGBoost 模型: 树集成(Tree Ensemble). 树集成就是分类与回归树(classification and regression trees, CART)的集合. 这里有一个简单的例子, 利用 CART 对一个人是否喜欢电脑游戏进行分类.\n",
    "\n",
    "![2.png](./resources/2.png)\n",
    "\n",
    "我们将家庭成员分类到不同的叶子节点中, 并且赋予对应叶子节点的分数. CART 与普通决策树不同, 每个叶子节点对应一个实数, 相比于普通决策树叶子节点对应一个类别来说, CART 能够给出超出类别的更丰富的解释. 这也使得统一优化(Unified Optimization)更容易.\n",
    "\n",
    "通常, 单一的树在实践中不够强大, 在实际中, 常常使用所谓的树集成模型, 将多棵树的结果合成得到最终预测结果.\n",
    "\n",
    "![3.png](./resources/3.png)\n",
    "\n",
    "上图的例子是两棵树的集成. 模型的最终结果由两颗树的结果相加. 如果你查看这个例子, 一个重要的事实是: 两棵树试图相互互补. 数学上, 模型的表示是: \n",
    "\n",
    "$$\\hat{y}_i = \\sum_{k=1}^K f_k(x_i), f_k\\in F$$\n",
    "\n",
    "这里, $K$ 是树的数目, $f$ 是函数空间 $F$ 中的一个函数, 函数空间 $F$ 是所有可能的 CARTs 的集合. 因此, 我们的优化目标可以被表示成:\n",
    "\n",
    "$$obj(\\theta) = \\sum_i^n l(y_i, \\hat{y}_i) + \\sum_{k=1}^K \\Omega(f_k)$$\n",
    "\n",
    "这里有一个问题, 什么是随机森林? 随机森林就是树集成! 所以随机森林和提升树在模型方面没有差别, 差别在于我们如何训练它们. 这意味着, 如果你写一个树集成的程序, 你只需要写一颗树即可, 然后该树对随机森利和提升树都试用. \n",
    "\n",
    "## 3. 树提升(Tree Boosting)\n",
    "***\n",
    "在介绍模型之后, 让我们开始训练部分. 我们应该如何生成树呢? 和其他所有监督学习模型一样, 答案是: 定义一个目标函数, 然后优化它! 假设我们有如下的目标函数(记住它通常需要包含训练损失和正则化项)\n",
    "\n",
    "$$obj = \\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t)}) + \\sum_{i=1}^t \\Omega(f_i)$$\n",
    "\n",
    "### 3.1 累积训练(Additive Training)\n",
    "***\n",
    "首先, 第一个问题是: 树的参数是什么? 你会发先我们需要学习的是那些函数 $f_i$, 每一个函数包含树的结构和叶子节点的分数. 相比于传统的优化问题能够通过求梯度来进行, 树的优化更难. 将所有的树同时生成不是一件容易的事. 相反, 我们使用一种累积的策略: 固定已经生成的树, 然后每次添加一颗新树. 我们用 $\\hat{y}_i^{(t)}$ 来表示第 $t$ 颗树的预测值, 所以有如下: \n",
    "\n",
    "$$\\hat{y}_i^{(0)} = 0$$\n",
    "\n",
    "$$\\hat{y}_i^{(1)} = f_1(x_i) = \\hat{y}_i^{(0)} + f_1(x_i)$$\n",
    "\n",
    "$$\\hat{y}_i^{(2)} = f_1(x_i) + f_2(x_i) = \\hat{y}_i^{(1)} + f_2(x_i)$$\n",
    "\n",
    "$$...$$\n",
    "\n",
    "$$\\hat{y}_i^{(t)} = \\sum_{k=1}^t f_k(x_i) = \\hat{y}_i^{(t-1)} + f_t(x_i)$$\n",
    "\n",
    "进一步追问, 在每一步中, 我们想生成哪颗树? 自然是添加最优化我们目标函数的那颗.\n",
    "\n",
    "$$obj^{(t)} = \\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t)}) + \\sum_{i=1}^t \\Omega(f_i)$$\n",
    "\n",
    "$$= \\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t-1)} + f_t(x_i)) + \\Omega(f_t) + constant$$\n",
    "\n",
    "如果使用 MSE 作为损失函数, 以上公式变成如下形式:\n",
    "\n",
    "$$obj^{(t)} = \\sum_{i=1}^n (y_i - (\\hat{y}_i^{(t-1)} + f_t(x_i)))^2 + \\sum_{i=1}^t \\Omega(f_i)$$\n",
    "\n",
    "$$= \\sum_{i=1}^n [2(\\hat{y}_i^{(t-1)} - y_i)f_t(x_i) + f_t(x_i)^2] + \\Omega(f_t) + constant$$\n",
    "\n",
    "可以看到, 以上目标函数当损失函数是 MSE 时, 形式非常友好, 只有一个一阶项(通常称为残差)和一个二次项. 对于其它损失函数(例如: logistic loss), 是不容易得到如此好的形式的. 所以, 一般的情况, 我们取损失函数的二阶泰勒展式:\n",
    "\n",
    "$$obj^{t} = \\sum_{i=1}^n [l(y_i, \\hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \\frac{1}{2}h_i f_t^2(x_i)] + \\Omega(f_t) + constant$$\n",
    "\n",
    "这里, $g_i$ 和 $h_i$ 定义如下:\n",
    "\n",
    "$$g_i = \\partial_{\\hat{y}_i^{(t-1)}}l(y_i, \\hat{y}_i^{(t-1)})$$\n",
    "\n",
    "$$h_i = \\partial_{\\hat{y}_i^{(t-1)}}^2 l(y_i, \\hat{y}_i^{(t-1)})$$\n",
    "\n",
    "在去除所有的常量项之后, 步骤 $t$ 的目标函数变成:\n",
    "\n",
    "$$\\sum_{i=1}^n [g_i f_t(x_i) + \\frac{1}{2}h_i f_t^2(x_i)] + \\Omega(f_t)$$\n",
    "\n",
    "上式就是我们生成新树时的优化目标. 这个定义的优点是: 它仅仅依赖 $g_i$ 和 $h_i$. 这就是为什么 XGBoost 支持自定义损失函数的原因所在. 我们能够使用相同的 solver(优化方法) 以 $g_i$ 和 $h_i$ 作为输入, 来优化每一个损失函数, 包括: logistic regression 和 weighted logistic regression.\n",
    "\n",
    "### 3.2 模型复杂度(Model Complexity)\n",
    "***\n",
    "我们已经介绍了训练步骤, 但是等一下, 这儿还有一件重要的事情: 正则化项! 我们需要定义树的复杂度 $\\Omega(f)$. 为此, 让我们首先细化树的定义 $f(x)$ 如下:\n",
    "\n",
    "$$f_t(x) = \\omega_{q(x)}, \\omega \\in R^T, q: R^d\\to\\{1, 2, ..., T\\}$$\n",
    "\n",
    "这里, $\\omega$ 是叶子节点的得分向量, $q$ 是将每个样本分配到对应叶子节点的函数, $T$ 是叶子节点的数目. 在 XGBoost 中, 我们定义复杂度如下:\n",
    "\n",
    "$$\\Omega(f) = \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T \\omega_j^2$$\n",
    "\n",
    "当然, 这里不止一种定义方法, 但这种定义在实践中效果很好. 正则化项是大多数树软件包不够重视的, 甚至直接忽略的地方. 这是因为传统的树生成仅仅强调提高节点的纯度, 而将模型复杂度用启发式算法来控制. 通过正式的定义模型复杂度, 我们能够清楚的知道我们正在学习什么, 并且这种定义也的确在实践中工作很好.\n",
    "\n",
    "### 3.3 树结构的评价指标(The Structure Score)\n",
    "***\n",
    "这块儿的推导有点复杂(magical), 通过将上一节中定义的模型函数和模型复杂度函数带入目标函数, 我们得到第 $t$ 颗树的目标函数如下:\n",
    "\n",
    "$$obj^{(t)} \\approx \\sum_{i=1}^n [g_i\\omega_{q(x_i)} + \\frac{1}{2}h_i \\omega_{q(x_i)}^2] + \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T \\omega_j^2$$\n",
    "\n",
    "$$= \\sum_{j=1}^T [(\\sum_{i \\in I_j} g_i) \\omega_j + \\frac{1}{2} (\\sum_{i \\in I_j} h_i + \\lambda)\\omega_j^2] + \\gamma T$$\n",
    "\n",
    "这里, $I_j = \\{i\\mid q(x_i)=j\\}$ 是分配到第 $j$ 个叶子节点的样本的索引的集合. 注意: 在第二行我们改变了求和索引, 因为在同一叶子节点中的所有样本获得同样的分数. 我们进一步简化表达式, 此处定义 $G_j = \\sum_{i \\in I_j} g_i$ 和 $H_j = \\sum_{i \\in I_j} h_i$,\n",
    "\n",
    "$$obj^{(t)} = \\sum_{j=1}^T[G_j \\omega_j + \\frac{1}{2}(H_j + \\lambda)\\omega_j^2] + \\gamma T$$\n",
    "\n",
    "在上式中, $\\omega_j$ 相对其它变量是独立的(没有函数关系), 因此 $G_j \\omega_j + \\frac{1}{2}(H_j + \\lambda)\\omega_j^2$ 是一个关于 $\\omega_j$ 的二次函数, 因此对于给定的 $q(x)$, 极大值点 $\\omega_j$ 和目标函数的极小值分别是:\n",
    "\n",
    "$$\\omega_j^* = -\\frac{G_j}{H_j + \\lambda}$$\n",
    "\n",
    "$$obj^* = -\\frac{1}{2}\\sum_{j=1}^T \\frac{G_j^2}{H_j + \\lambda} + \\gamma T$$\n",
    "\n",
    "后一个公式可作为树结构 $q(x)$ 好坏程度的指标.\n",
    "\n",
    "![4.png](./resources/4.png)\n",
    "\n",
    "如果以上分析听起来有点复杂, 让我们看一下上图, 看看上式的指标是怎么计算的. 基本上是这样的, 对于一个给定的树结构, 我们将 $g_i$ 和 $h_i$ 计算值分配到每个叶子节点中, 然后对每个叶子节点求和得到 $G_j$ 和 $H_j$, 进一步带入上式求和得到树结构好坏的指标. 这个指标与决策树中常用的不纯度指标(impurity measure)类似, 但是除此之外, 该指标还考虑了模型复杂度.\n",
    "\n",
    "### 3.4 学习树结构(Learn the tree structure)\n",
    "***\n",
    "现在我们有了评价树结构的指标, 理想情况下, 可以枚举所有可能的树结构然后跳出最好的一颗. 但在实践中, 枚举方法实现起来困难, 所以我们将试图一次优化一层树结构. 也就是试图将一个叶节点分成两个叶节点, 目标函数增益是:\n",
    "\n",
    "$$Gain = \\frac{1}{2}[\\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{(G_L + G_R)^2}{H_L + H_R + \\lambda}] - \\gamma$$\n",
    "\n",
    "该公式能够被分解为: 1) 新生成左叶子节点得分, 2) 新生成右叶子节点得分, 3) 原来叶子节点得分, 4)附加叶子节点的正则化项. 由上式得到重要结论: 如果 $Gain$ 为负数, 生成新叶子节点后反效果反而变差了. 这就是基于树的模型中的剪枝方法.\n",
    "\n",
    "对于真实的样本数据, 我们通常希望找到一个最佳切分点. 为了高效的寻找切分点, 我们像下图一样, 将所有实例按序排好.\n",
    "\n",
    "![5.png](./resources/5.png)\n",
    "\n",
    "一次从左到右的循环足以计算所有可能切分结果的目标函数得分, 这使我们能够高效地找到最佳切分.\n",
    "\n",
    "## 4. 最后说一说XGBoost(Final words on XGBoost)\n",
    "***\n",
    "现在你理解了什么是提升树, 你可能会问, 关于 XGBoost 的介绍在哪里呢? XGBoost 就是一个基于该教程介绍的原则的工具库. 更重要的是, 该库在开发时深入考虑了系统优化和机器学习的相关原则. 该库的目标是将机器的计算性能利用到极致, 为了提供一个可扩展的(scalable), 可移植的(portable), 精确的函数库.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
